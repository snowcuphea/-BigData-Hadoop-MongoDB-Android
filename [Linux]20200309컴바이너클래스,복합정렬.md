HDFS는 파일시스템이지만, 물리적으로 확인할 수 있는것이 아니다. (블럭단위로 쪼개져있기때문에)

### MapReduce 프레임워크

* 맵리듀스 : 프레임워크. 대용량 데이터를 처리하기 위함.

* 맵리듀스도 마스터, 슬레이브 구조로 되어있음

* 맵퍼가처리한일을 리듀서한테 전달을 하는데, 매퍼에서 적용한 것을 리듀서에서 바로 처리하면 되는데, 전달시킬 때 네트워크로 전송이 된다.(패킷단위, serialized) 그 때 네트웤 부하에 대한 이슈로 문제가 생길 수 있다.

* 맵리듀스의 기능 : 데이터 분류, 집계하는 것

* 내가 돌리지 않아도 매퍼를 돌리고 나오면 merge되고 sort된다(프레임워크라서 자동으로). (shuffle) 셔플링을 거쳐서 배열로 나온다. 
  shuffle을 커스터마이징해서 내가원하는 형태로 조절한다. mapper를 여러개 만든다던가. 출력을 원하는 형태로 한다던가

![image-20200309094953548](images/image-20200309094953548.png)

사용한 리듀서 개수만큼 나온다. (r이 리듀스를 의미)



![image-20200309102514738](images/image-20200309102514738.png)

sts에서 remote controller를 통해 하둡으로 csv파일 옮기고, 옮긴 파일을 /air 폴더를 생성 후 그 안에 넣는다.
다 넣었으면, 홈디렉토리 파일상태로 있는 csv파일의 크기가 부담스럽기 때문에 휴지통으로 버리고 비워준다. (로컬에서도 지워준다. )



---

airdriver 실행

![image-20200309103419227](images/image-20200309103419227.png)





잡트래커로 진입

http://hadoop01:50030/jobtracker.jsp

![image-20200309104723235](images/image-20200309104723235.png)

![image-20200309104833656](C:\Users\student\AppData\Roaming\Typora\typora-user-images\image-20200309104833656.png)



### 컴바이너 클래스

맵 태스크의 출력데이터는 네트워크를 통해 리듀스 태스크로 전달되는데, 이 과정을 셔플 이라고 한다.

네트워크를 통해 데이터가 전송되기 때문에 전송할 데이터의 크기를 줄일수록 전체 잡의 성능이 좋아진다.

컴바이너의 역할은 다음과 같다. 

* 셔플할 데이터의 크기를 줄인다.
* 매퍼으 출력데이터를 입력데이터로 전달받아 연산 수행
* 미니 리듀서

---

실습

---

리듀서 코드

![image-20200309113108701](images/image-20200309113108701.png)



그 이후 드라이버 소스에서 컴파이너클래스 등록을 해준다.

**![image-20200309113151712](images/image-20200309113151712.png)**



하둡에서 실행하려면 jar파일을 실행해야 한다. 

따라서 jar파일로 묶어서 build path에 추가해준다. 



![image-20200309113510761](images/image-20200309113510761.png)

![image-20200309113537958](images/image-20200309113537958.png)



![image-20200309113600461](images/image-20200309113600461.png)

![image-20200309113611358](images/image-20200309113611358.png)

![image-20200309113750467](images/image-20200309113750467.png)

![image-20200309113647258](images/image-20200309113647258.png)

Referenced Library에 mapred-exam.jar보면 생성된 것을 확인할 수 있다.







한 번 실행하고 오류가 뜨면, run configuration해준다.

![image-20200309113317205](images/image-20200309113317205.png)

---

실행 후 하둡에서 확인해ㅔ보면

컴바이너 쓰기 전에는 : 

![image-20200309114508985](images/image-20200309114508985.png)

쓰고난 후에는

![image-20200309114527555](images/image-20200309114527555.png)

차이가 난다. 

이 외에도 여러가지 차이 남 (살펴보기) => 더 효율적이다.



---

### 셔플 커스터마이징

같은것끼리모아야 네트웤 부하가 덜걸리기 때문에 같은것 끼리 모아서 정렬 후 리듀서로 넘긴다. 

이 부분을 내 기준에 의해 원하는 부분을 merge시키고 정렬할 수 있다. 



같은 키를 갖고 있는 

ㅁ머신이 3대가 있으면 각각 받아서 취합하는게 아니라, 같은 종류의 키를 내부에서 모은다. 



![image-20200309133044287](images/image-20200309133044287.png)

이런 애를 1월부터 12월로 잘 나오게 정렬하려고 한다. 

---

### 정렬 - 보조 정렬 p178

1. 복합키 정의 ( 사용자 정의 키 )
   - WritableComparable 인터페이스 구현 





매퍼에서 데이터 나오면, 

year끼리 계산을 해서 어느 태스크 로 보내야하는지결정되고 모인다. 

메모리 버퍼에 쌓고 같은 것끼리 모아놓은 상태 

#### 

---

### 정렬 실습



#### 복합키

![image-20200309164531202](images/image-20200309164531202.png)

![image-20200309164558381](images/image-20200309164558381.png)

WritableComparable을 상속. 그리고 생성자 만들어주고, set,get, tostring등 적어준다.



#### 매퍼

![image-20200309165013683](images/image-20200309165013683.png)

매퍼를 거쳐서 출력되는 output 타입을 내가 정의한 복합키 형식(CustomKey)으로 해준다.





#### 파티셔너 

![image-20200309163851180](images/image-20200309163851180.png)





#### 그룹키비교기 

![image-20200309163821502](images/image-20200309163821502.png)



#### 복합키 비교기

![image-20200309164333946](images/image-20200309164333946.png)





#### 드라이버

![image-20200309164911371](images/image-20200309164911371.png)

정의한 클래스를 드라이버에 등록해준다.





#### 리듀서

![image-20200309171945908](images/image-20200309171945908.png)



---

2020/03/11

### context

![image-20200311092059558](images/image-20200311092059558.png)

* mapper, reducer에서 context에 write를 한다. 

* 이너클래스 이다. : 클래스 안에서 정의되는 클래스

  ```
  class mapper{
  	class context{
  	
  	}
  }
  ```



----

### 데이터 처리 과정

![KakaoTalk_20200311_095442236](images/KakaoTalk_20200311_095442236.jpg)

데이터노드에 태스크트래커가 들어가있고, 

로컬디스크 : 하둡이 동작할 때 사이즈를 판단해서 사이즈가 크지 않으면 메모리에 올려서 처리를 하다가 작업이완료 되면 사용했던 임시 데이터를 삭제한다.

디스크에 쓰여져있는 데이터를 읽어가지고 오는 기본 처리는 InputFormat이다. InputFormat을 통해 split이라고 표현하는 데이터가 들어온다. 블럭단위의 데이터를 split이라고 함

데이터가 쪼개져서 들어오면 레코드들을 읽어주는 작업을 한다. (readRecord)

거기서 map들이 실행이 된다.

맵이 다 처리가 되면 어디로 보내야 하지? 하는 기능이 바로 파티셔너

이 동작이 하둡머신마다 일어나고 있다. 

파티셔너가 된 후 그룹핑과 정렬 작업이 일어난다.

파티셔너의 역할은 ? 어떤 리듀스태스크로 보낼지 계산 및 판단하는 작업. 모아주는 작업

같은 것끼리 모아주려고 기본으로 설정되어잇는게 특정 키를 구해서, 해시코드를 구해서, 어떤 리듀서로 보낼 지 그 갯수만큼 나눈다. (%연산 이용)

그 과정에서 네트웤을 통해 산출물을 서로 교환한다. (네트워크 통신)

그 작업잍 끝나면 reducer한테 데이터가 전달이 된다. 

리듀서의 역할은 각 노드(hdoop02, hdoop03, 04) 맵에서 들어온 데이터를 처리. 디스크에서 처리를 하는데, 

만약 Year를 기준으로 그룹핑을 했으면 



하나는 커스텀키를 만들었고, 그 커스텀키에서 어떤 정렬을 할지 

키를 여러개 주고 여러 형태로 데이터를 정렬하겠다.

첫 번째 기준으로 그룹핑(걸러야 하는데), 우리가실습했던 것은 Year로 그룹핑

먼저 year그룹핑으로 1987, 1988 이런식으로 나눈 뒤(그룹을 나눠준 뒤)

그 담엔 month로 그룹핑 오름차순 되도록 

groupkeycomparator랑 customkeycomparator를 사용한 것이다.



(map과 리듀서의 output은 key와  value로 정의되어지는데, 그 타입은 자유롭게 정의할 수 있다. )

---



### Reduce 실행 횟수 : advancedMapReduce / mapreduce.basic  패키지

Reduce는 하나지만, 하나를 가지고 reduce가 계속 호출되는데 누적값을 알아보자

![image-20200311101339916](images/image-20200311101339916.png)

![image-20200311101302585](images/image-20200311101302585.png)

실행결과를 보면 전달되는 key(a, book, java....) 개수만큼 reduce가 계속 호출됨을 알 수 있다. 



동일한 커스텀키를 가지고 사용하기 때문에 hashcode값이 같다.

![image-20200311104907654](images/image-20200311104907654.png)







![image-20200311105755918](images/image-20200311105755918.png)

4번 머신의 /home hadoop hadoop1.2.1의 log로 가보자



![image-20200311105727819](images/image-20200311105727819.png)



![image-20200311105854653](images/image-20200311105854653.png)

![image-20200311105927935](images/image-20200311105927935.png)

stdout파일을 보면 sts에서 sysout한 결과 나온다. 



---

![image-20200311111631213](images/image-20200311111631213.png)

![image-20200311111904365](images/image-20200311111904365.png)

CustomKey에 Long writable인 mapkey를 추가







![image-20200311111723476](images/image-20200311111723476.png)

맵에서 내보낼때마다 맵키가 달라진다. mapkey에 key 값 등록하고 있다. (LongWritable key는 라인넘버)

key를 보기 위한 세팅을 하고 있는 것이다. (map이 달라지는지를 보고 싶어서)

customkey에 매번 새로운 값이 들어오는지 확인하기 위한 작업 

![image-20200311112135431](images/image-20200311112135431.png)

리듀서에 key.getMapkey()추가



![image-20200311112558407](images/image-20200311112558407.png)

해쉬코드는 같은 객체를 사용하지만, map에서 전달한 키는 계속 다른 값이 들어오고 있음을 알 수 있다.

---

실습 



reduce안에서 출력 형태를 조절하여 해보자.

